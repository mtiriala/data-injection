# üìä Syst√®me de Monitoring d'Ingestion de Donn√©es

## üéØ Vue d'ensemble

Ce projet impl√©mente un syst√®me complet de monitoring en temps r√©el pour l'ingestion de donn√©es, utilisant une architecture moderne bas√©e sur Kafka, Loki, Promtail et Grafana. Le syst√®me surveille automatiquement les pipelines de donn√©es, d√©tecte les anomalies et g√©n√®re des alertes intelligentes.

## üèóÔ∏è Architecture

```
S3 ‚Üí Producer.py ‚Üí Kafka ‚Üí Promtail ‚Üí Loki ‚Üí Grafana
                                              ‚Üì
                                         Dashboards + Alertes
```

## üìÅ Structure du Projet

### üîß **Fichiers de Configuration Principaux**

#### `docker-compose.yml`
**R√¥le**: Orchestrateur principal du syst√®me
- **Zookeeper**: Coordination des services Kafka
- **Kafka**: Bus de messages pour l'ingestion en temps r√©el
- **Loki**: Base de donn√©es de logs haute performance
- **Promtail**: Agent de collecte et transformation des logs
- **Grafana**: Interface de visualisation et d'alerting

#### `producer.py`
**R√¥le**: G√©n√©rateur de donn√©es d'ingestion
- T√©l√©charge les logs depuis S3 (`s3://my12data/logs.json`)
- Transforme et envoie 72 logs vers Kafka
- Simule des succ√®s (71) et √©checs (1) r√©alistes
- Point d'entr√©e pour tester le syst√®me

#### `promtail-config.yml`
**R√¥le**: Configuration de l'agent de collecte
- **Source**: Topic Kafka `ingestion-logs`
- **Transformation**: Extraction des champs JSON (`etat`, `source`, `entreprise`, `zone`)
- **Destination**: Loki avec labels structur√©s
- **Consumer Group**: `promtail-consumer` pour la persistance

#### `loki-config.yml`
**R√¥le**: Configuration de la base de donn√©es de logs
- Stockage optimis√© pour les logs temporels
- Indexation par labels pour requ√™tes rapides
- R√©tention et compression automatiques

### üìä **Dashboards Grafana** (`grafana-provisioning/dashboards/`)

#### `1-ingestion-health.json`
**R√¥le**: Dashboard principal de sant√© du syst√®me
- **8 panels** de monitoring en temps r√©el:
  - Succ√®s/√âchecs (compteurs)
  - Taux d'√©chec (pourcentage)
  - Performance (p95 dur√©e, m√©moire max)
  - Timeline visuelle (SUCCESS vs FAILED)
  - Top sources par performance
  - Table des derni√®res erreurs

#### `2-errors-slas.json`
**R√¥le**: Monitoring des SLAs et erreurs critiques
- **3 panels** sp√©cialis√©s:
  - Taux d'√©chec global et par source
  - MTTR (Mean Time To Recovery)
  - SLO fra√Æcheur (alertes si pipeline silencieux)

#### `3-performance-resource.json`
**R√¥le**: Analyse des performances et ressources
- **3 panels** de performance:
  - Percentiles de dur√©e (p50/p95/p99)
  - D√©bit par source (#ex√©cutions/5min)
  - Consommation CPU et m√©moire

#### `4-logs-debugging.json`
**R√¥le**: Interface de d√©bogage avanc√©
- **1 panel** table filtrable:
  - Colonnes: D√©but, Fin, Dur√©e, CPU, M√©moire, Description
  - Recherche et filtrage en temps r√©el
  - Export des donn√©es pour analyse

### üö® **Syst√®me d'Alerting** (`grafana-provisioning/alerting/`)

#### `1-echec-detecte.yml`
**R√¥le**: D√©tection d'√©checs critiques
- **Condition**: ‚â•1 log FAILED en 5 minutes
- **Seuil**: Critique (intervention imm√©diate)
- **Requ√™te**: `{job="kafka-logs"} |= "FAILED"`

#### `2-taux-echec-eleve.yml`
**R√¥le**: Surveillance du taux d'erreur global
- **Condition**: Taux d'√©chec >2% pendant 15 minutes
- **Seuil**: Warning (surveillance renforc√©e)
- **Calcul**: Ratio √©checs/total avec protection division par z√©ro

#### `3-source-muette.yml`
**R√¥le**: D√©tection de sources silencieuses
- **Condition**: Aucune ex√©cution depuis 75 minutes
- **Seuil**: Critique (pipeline possiblement arr√™t√©)
- **Requ√™te**: `count_over_time({job="kafka-logs"}[75m])`

#### `4-latence-degradee.yml`
**R√¥le**: Monitoring des performances
- **Condition**: Latence p95 >10 secondes
- **Seuil**: Warning (d√©gradation performance)
- **M√©trique**: Bas√©e sur le d√©bit (`rate()`)

#### `5-surconsommation-ressources.yml`
**R√¥le**: Surveillance des ressources syst√®me
- **Conditions**: 
  - M√©moire >150MB
  - CPU >60 secondes
- **Seuil**: Warning (optimisation requise)
- **Proxy**: Utilise le d√©bit comme indicateur

### ‚öôÔ∏è **Configuration de Provisioning**

#### `datasources/loki.yaml`
**R√¥le**: Configuration automatique de la source de donn√©es
- **URL**: `http://loki:3100` (r√©seau Docker)
- **Type**: Loki (logs)
- **UID**: `Loki` (r√©f√©rence dans les dashboards)

#### `dashboards/dashboards.yml`
**R√¥le**: Provisioning automatique des dashboards
- **Dossier**: `data-dashboard`
- **Auto-import**: Tous les fichiers JSON
- **Mise √† jour**: Automatique au red√©marrage

#### `alerting/alerting.yml`
**R√¥le**: Configuration du syst√®me d'alerting
- **Dossier**: `data-alerts`
- **R√®gles**: Auto-chargement des fichiers YAML
- **Notifications**: Email (configurable)

## üöÄ **Utilisation**

### D√©marrage du Syst√®me
```bash
cd /home/ubuntu/data-ingestion
docker-compose up -d
```

### Injection de Donn√©es
```bash
python3 producer.py
```

### Acc√®s aux Interfaces
- **Grafana**: http://16.52.119.70:3000 (admin/admin)
- **Loki**: http://16.52.119.70:3100
- **Kafka**: 16.52.119.70:9092

## üìà **M√©triques Surveill√©es**

### Indicateurs de Sant√©
- **Succ√®s/√âchecs**: Comptage en temps r√©el
- **Taux d'erreur**: Pourcentage avec seuils
- **Disponibilit√©**: D√©tection de sources muettes

### Performance
- **Latence**: Percentiles p50/p95/p99
- **D√©bit**: Ex√©cutions par minute
- **Ressources**: CPU et m√©moire (proxy)

### SLAs
- **MTTR**: Temps moyen de r√©cup√©ration
- **Fra√Æcheur**: D√©lai depuis derni√®re ex√©cution
- **Qualit√©**: Taux de succ√®s par source

## üîß **Maintenance**

### Nettoyage des Donn√©es
```bash
docker-compose down
docker volume rm data-ingestion_loki-data data-ingestion_kafka-data
docker-compose up -d
```

### Red√©marrage apr√®s EC2
```bash
docker-compose up -d
sleep 30
python3 producer.py
```

## üéØ **Cas d'Usage**

1. **Monitoring Op√©rationnel**: Surveillance 24/7 des pipelines
2. **D√©tection d'Anomalies**: Alertes automatiques sur √©checs
3. **Analyse de Performance**: Optimisation des sources lentes
4. **D√©bogage**: Investigation des erreurs avec logs d√©taill√©s
5. **Reporting**: M√©triques SLA pour management

## üèÜ **Avantages**

- **Temps R√©el**: D√©tection instantan√©e des probl√®mes
- **Scalabilit√©**: Architecture Kafka haute performance
- **Automatisation**: Provisioning complet via code
- **Flexibilit√©**: Dashboards et alertes configurables
- **Fiabilit√©**: Persistance des donn√©es et √©tats